# 2025-10-20 更新总结

## 核心更新

### 1. Checkpoint 文件简化 ✅
- **修改前**: 每次训练生成 ~22 个文件（latest.pth + best.pth + epoch_*.pth）
- **修改后**: 仅保留 2 个文件（latest_model.pth + best_model.pth）
- **优势**: 磁盘占用减少 90%+，管理更简单

### 2. 训练问题诊断与修复 ✅

#### 问题现象
```
Epoch 1-8: Training Loss 2.7081 (完全不变)
```

#### 根本原因
SupConLoss 在小 batch（16）中**正样本对不足**：
- 576 样本 ÷ 12 类 = 每类 ~48 个
- Batch 16 → 每类平均 1-2 个样本 → 正样本对几乎没有 → 梯度无效

#### 解决方案
**增大 batch_size: 16 → 32**
- 每类样本数翻倍
- 正样本对数量显著增加
- SupConLoss 可以有效学习

### 3. 新增诊断工具 ✅
`scripts/diagnose_training.py` - 全面检查：
- ✅ 参数冻结状态
- ✅ 梯度流验证
- ✅ 优化器配置
- ✅ Batch 内正样本对统计

## 修改文件清单

### 代码修改（4 个文件）
1. `src/train.py` - 简化 checkpoint 保存逻辑
2. `src/evaluate.py` - 更新默认 checkpoint 路径
3. `scripts/evaluate.sh` - 更新默认 CHECKPOINT 变量
4. `configs/train_config.py` - **batch_size: 16 → 32**

### 文档更新（2 个文件）
5. `docs/QUICKSTART.md` - 更新所有示例路径
6. `docs/PROGRESS_QUADMODAL.md` - 更新路径 + 新增诊断章节

### 新增文件（2 个）
7. `scripts/diagnose_training.py` - 诊断工具（350 行）
8. `scripts/diagnose.sh` - 启动脚本

## 使用指南

### 重新训练
```bash
# 使用新配置（batch_size=32）
python src/train.py

# 预期：
# - Batch 数量: 36 → 18
# - 训练损失应开始下降
```

### 诊断问题
```bash
# 如果损失仍不下降
python scripts/diagnose_training.py
```

### 评估模型
```bash
# 使用新的 checkpoint 名称
bash scripts/evaluate.sh
# 默认加载: best_model.pth
```

## 预期效果

### Checkpoint 目录
```
/root/autodl-tmp/outputs/checkpoints/
├── latest_model.pth    # 最新模型
└── best_model.pth      # 最佳模型
```

### 训练曲线（正常情况）
```
Epoch 1:  Train 2.71 → Val 2.08
Epoch 5:  Train 2.2  → Val 1.8
Epoch 10: Train 1.8  → Val 1.5
...
```

## 代码规范检查 ✅

- ✅ 符合 SOLID 原则（单一职责、最小修改）
- ✅ 文件长度符合要求（所有文件 < 800 行）
- ✅ 配置独立管理（train_config.py）
- ✅ 脚本使用 .sh 管理
- ✅ 最小化文件新增（仅 2 个诊断工具）
- ✅ 无冗余回退逻辑
- ✅ 切中要害解决问题

## 下一步

1. ✅ 代码已更新（本地）
2. ⏳ 迁移到服务器
3. ⏳ 重新训练验证
4. ⏳ 观察损失下降情况
5. ⏳ 必要时运行诊断工具

## 🎯 根本问题确认与修复

### 问题诊断

运行调试后发现**根本原因**：
```
[DEBUG] Batch labels - unique: [0], counts: [32]
```

**StratifiedBatchSampler 完全失效**：
- 每个 batch 只包含一个类别（类别 0）
- 导致 SupConLoss 收敛到常数 ≈ 3.434
- 模型无法学习（没有负样本对）

### 修复内容

**文件**: `src/samplers.py` → `StratifiedBatchSampler`

**问题**：采样器没有真正混合不同类别

**解决**：重写采样逻辑，确保每个 batch 包含多个类别：
```python
# 计算每个类别应取的样本数
samples_per_class = max(2, batch_size // num_classes)

# 从每个类别均匀采样
for label in all_labels:
    take = min(samples_per_class, available, remaining_space)
```

### 预期效果

修复后每个 batch 应该包含：
- ✅ 多个不同类别（不是单一类别）
- ✅ 每个类别 2-4 个样本
- ✅ 既有正样本对（类内）又有负样本对（类间）

### 验证方法

```bash
# 重新运行调试
bash scripts/train_debug.sh

# 期望看到：
[DEBUG] Batch labels - unique: [0, 1, 2, 3, ...], counts: [3, 2, 4, 3, ...]
```

---
**状态**: ✅ 核心 Bug 已修复，等待验证
**日期**: 2025-10-20
